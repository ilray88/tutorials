{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\0ilraypan\\python_work\\env\\tensorflow=1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-6266be39842f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mskimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mskimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a simple example of transfer learning using VGG.\n",
    "Fine tune a CNN from a classifier to regressor.\n",
    "Generate some fake data for describing cat and tiger length.\n",
    "\n",
    "Fake length setting:\n",
    "Cat - Normal distribution (40, 8)\n",
    "Tiger - Normal distribution (100, 30)\n",
    "\n",
    "The VGG model and parameters are adopted from:\n",
    "https://github.com/machrisaa/tensorflow-vgg\n",
    "\n",
    "Learn more, visit my tutorial site: [莫烦Python](https://morvanzhou.github.io)\n",
    "\"\"\"\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def download():     # download tiger and kittycat image\n",
    "    categories = ['tiger', 'kittycat']\n",
    "    for category in categories:\n",
    "        os.makedirs('./for_transfer_learning/data/%s' % category, exist_ok=True)\n",
    "        with open('./for_transfer_learning/imagenet_%s.txt' % category, 'r') as file:\n",
    "            urls = file.readlines()\n",
    "            n_urls = len(urls)\n",
    "            for i, url in enumerate(urls):\n",
    "                try:\n",
    "                    urlretrieve(url.strip(), './for_transfer_learning/data/%s/%s' % (category, url.strip().split('/')[-1]))\n",
    "                    print('%s %i/%i' % (category, i, n_urls))\n",
    "                except:\n",
    "                    print('%s %i/%i' % (category, i, n_urls), 'no image')\n",
    "\n",
    "\n",
    "def load_img(path):\n",
    "    img = skimage.io.imread(path)\n",
    "    img = img / 255.0\n",
    "    # print \"Original Image Shape: \", img.shape\n",
    "    # we crop image from center\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    # resize to 224, 224\n",
    "    resized_img = skimage.transform.resize(crop_img, (224, 224))[None, :, :, :]   # shape [1, 224, 224, 3]\n",
    "    return resized_img\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    imgs = {'tiger': [], 'kittycat': []}\n",
    "    for k in imgs.keys():\n",
    "        dir = './for_transfer_learning/data/' + k\n",
    "        for file in os.listdir(dir):\n",
    "            if not file.lower().endswith('.jpg'):\n",
    "                continue\n",
    "            try:\n",
    "                resized_img = load_img(os.path.join(dir, file))\n",
    "            except OSError:\n",
    "                continue\n",
    "            imgs[k].append(resized_img)    # [1, height, width, depth] * n\n",
    "            if len(imgs[k]) == 400:        # only use 400 imgs to reduce my memory load\n",
    "                break\n",
    "    # fake length data for tiger and cat\n",
    "    tigers_y = np.maximum(20, np.random.randn(len(imgs['tiger']), 1) * 30 + 100)\n",
    "    cat_y = np.maximum(10, np.random.randn(len(imgs['kittycat']), 1) * 8 + 40)\n",
    "    return imgs['tiger'], imgs['kittycat'], tigers_y, cat_y\n",
    "\n",
    "\n",
    "class Vgg16:\n",
    "    vgg_mean = [103.939, 116.779, 123.68]\n",
    "\n",
    "    def __init__(self, vgg16_npy_path=None, restore_from=None):\n",
    "        # pre-trained parameters\n",
    "        try:\n",
    "            self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "        except FileNotFoundError:\n",
    "            print('Please download VGG16 parameters from here https://mega.nz/#!YU1FWJrA!O1ywiCS2IiOlUCtCpI6HTJOMrneN-Qdv3ywQP5poecM\\nOr from my Baidu Cloud: https://pan.baidu.com/s/1Spps1Wy0bvrQHH2IMkRfpg')\n",
    "\n",
    "        self.tfx = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "        self.tfy = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "        # Convert RGB to BGR\n",
    "        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=self.tfx * 255.0)\n",
    "        bgr = tf.concat(axis=3, values=[\n",
    "            blue - self.vgg_mean[0],\n",
    "            green - self.vgg_mean[1],\n",
    "            red - self.vgg_mean[2],\n",
    "        ])\n",
    "\n",
    "        # pre-trained VGG layers are fixed in fine-tune\n",
    "        conv1_1 = self.conv_layer(bgr, \"conv1_1\")\n",
    "        conv1_2 = self.conv_layer(conv1_1, \"conv1_2\")\n",
    "        pool1 = self.max_pool(conv1_2, 'pool1')\n",
    "\n",
    "        conv2_1 = self.conv_layer(pool1, \"conv2_1\")\n",
    "        conv2_2 = self.conv_layer(conv2_1, \"conv2_2\")\n",
    "        pool2 = self.max_pool(conv2_2, 'pool2')\n",
    "\n",
    "        conv3_1 = self.conv_layer(pool2, \"conv3_1\")\n",
    "        conv3_2 = self.conv_layer(conv3_1, \"conv3_2\")\n",
    "        conv3_3 = self.conv_layer(conv3_2, \"conv3_3\")\n",
    "        pool3 = self.max_pool(conv3_3, 'pool3')\n",
    "\n",
    "        conv4_1 = self.conv_layer(pool3, \"conv4_1\")\n",
    "        conv4_2 = self.conv_layer(conv4_1, \"conv4_2\")\n",
    "        conv4_3 = self.conv_layer(conv4_2, \"conv4_3\")\n",
    "        pool4 = self.max_pool(conv4_3, 'pool4')\n",
    "\n",
    "        conv5_1 = self.conv_layer(pool4, \"conv5_1\")\n",
    "        conv5_2 = self.conv_layer(conv5_1, \"conv5_2\")\n",
    "        conv5_3 = self.conv_layer(conv5_2, \"conv5_3\")\n",
    "        pool5 = self.max_pool(conv5_3, 'pool5')\n",
    "\n",
    "        # detach original VGG fc layers and\n",
    "        # reconstruct your own fc layers serve for your own purpose\n",
    "        self.flatten = tf.reshape(pool5, [-1, 7*7*512])\n",
    "        self.fc6 = tf.layers.dense(self.flatten, 256, tf.nn.relu, name='fc6')\n",
    "        self.out = tf.layers.dense(self.fc6, 1, name='out')\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        if restore_from:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(self.sess, restore_from)\n",
    "        else:   # training graph\n",
    "            self.loss = tf.losses.mean_squared_error(labels=self.tfy, predictions=self.out)\n",
    "            self.train_op = tf.train.RMSPropOptimizer(0.001).minimize(self.loss)\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def max_pool(self, bottom, name):\n",
    "        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def conv_layer(self, bottom, name):\n",
    "        with tf.variable_scope(name):   # CNN's filter is constant, NOT Variable that can be trained\n",
    "            conv = tf.nn.conv2d(bottom, self.data_dict[name][0], [1, 1, 1, 1], padding='SAME')\n",
    "            lout = tf.nn.relu(tf.nn.bias_add(conv, self.data_dict[name][1]))\n",
    "            return lout\n",
    "\n",
    "    def train(self, x, y):\n",
    "        loss, _ = self.sess.run([self.loss, self.train_op], {self.tfx: x, self.tfy: y})\n",
    "        return loss\n",
    "\n",
    "    def predict(self, paths):\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        for i, path in enumerate(paths):\n",
    "            x = load_img(path)\n",
    "            length = self.sess.run(self.out, {self.tfx: x})\n",
    "            axs[i].imshow(x[0])\n",
    "            axs[i].set_title('Len: %.1f cm' % length)\n",
    "            axs[i].set_xticks(()); axs[i].set_yticks(())\n",
    "        plt.show()\n",
    "\n",
    "    def save(self, path='./for_transfer_learning/model/transfer_learn'):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(self.sess, path, write_meta_graph=False)\n",
    "\n",
    "\n",
    "def train():\n",
    "    tigers_x, cats_x, tigers_y, cats_y = load_data()\n",
    "\n",
    "    # plot fake length distribution\n",
    "    plt.hist(tigers_y, bins=20, label='Tigers')\n",
    "    plt.hist(cats_y, bins=10, label='Cats')\n",
    "    plt.legend()\n",
    "    plt.xlabel('length')\n",
    "    plt.show()\n",
    "\n",
    "    xs = np.concatenate(tigers_x + cats_x, axis=0)\n",
    "    ys = np.concatenate((tigers_y, cats_y), axis=0)\n",
    "\n",
    "    vgg = Vgg16(vgg16_npy_path='./for_transfer_learning/vgg16.npy')\n",
    "    print('Net built')\n",
    "    for i in range(100):\n",
    "        b_idx = np.random.randint(0, len(xs), 6)\n",
    "        train_loss = vgg.train(xs[b_idx], ys[b_idx])\n",
    "        print(i, 'train loss: ', train_loss)\n",
    "\n",
    "    vgg.save('./for_transfer_learning/model/transfer_learn')      # save learned fc layers\n",
    "\n",
    "\n",
    "def eval():\n",
    "    vgg = Vgg16(vgg16_npy_path='./for_transfer_learning/vgg16.npy',\n",
    "                restore_from='./for_transfer_learning/model/transfer_learn')\n",
    "    vgg.predict(\n",
    "        ['./for_transfer_learning/data/kittycat/000129037.jpg', './for_transfer_learning/data/tiger/391412.jpg'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # download()\n",
    "    # train()\n",
    "    eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}