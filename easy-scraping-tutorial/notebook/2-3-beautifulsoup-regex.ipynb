{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup 解析网页: 正则表达"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"cn\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>爬虫练习 表格 table | 莫烦 Python</title>\n",
      "\n",
      "\t<style>\n",
      "\timg {\n",
      "\t\twidth: 250px;\n",
      "\t}\n",
      "\ttable{\n",
      "\t\twidth:50%;\n",
      "\t}\n",
      "\ttd{\n",
      "\t\tmargin:10px;\n",
      "\t\tpadding:15px;\n",
      "\t}\n",
      "\t</style>\n",
      "</head>\n",
      "<body>\n",
      "\n",
      "<h1>表格 爬虫练习</h1>\n",
      "\n",
      "<p>这是一个在 <a href=\"/\" >莫烦 Python</a> 的 <a href=\"/tutorials/data-manipulation/scraping/\" >爬虫教程</a>\n",
      "\t里无敌简单的网页, 所有的 code 让你一目了然, 清晰无比.</p>\n",
      "\n",
      "<br>\n",
      "<table id=\"course-list\">\n",
      "\t<tr>\n",
      "\t\t<th>\n",
      "\t\t\t分类\n",
      "\t\t</th><th>\n",
      "\t\t\t名字\n",
      "\t\t</th><th>\n",
      "\t\t\t时长\n",
      "\t\t</th><th>\n",
      "\t\t\t预览\n",
      "\t\t</th>\n",
      "\t</tr>\n",
      "\n",
      "\t<tr id=\"course1\" class=\"ml\">\n",
      "\t\t<td>\n",
      "\t\t\t机器学习\n",
      "\t\t</td><td>\n",
      "\t\t\t<a href=\"/tutorials/machine-learning/tensorflow/\">\n",
      "\t\t\t\tTensorflow 神经网络</a>\n",
      "\t\t</td><td>\n",
      "\t\t\t2:00\n",
      "\t\t</td><td>\n",
      "\t\t\t<img src=\"/static/img/course_cover/tf.jpg\">\n",
      "\t\t</td>\n",
      "\t</tr>\n",
      "\n",
      "\t<tr id=\"course2\" class=\"ml\">\n",
      "\t\t<td>\n",
      "\t\t\t机器学习\n",
      "\t\t</td><td>\n",
      "\t\t\t<a href=\"/tutorials/machine-learning/reinforcement-learning/\">\n",
      "\t\t\t\t强化学习</a>\n",
      "\t\t</td><td>\n",
      "\t\t\t5:00\n",
      "\t\t</td><td>\n",
      "\t\t\t<img src=\"/static/img/course_cover/rl.jpg\">\n",
      "\t\t</td>\n",
      "\t</tr>\n",
      "\n",
      "\t<tr id=\"course3\" class=\"data\">\n",
      "\t\t<td>\n",
      "\t\t\t数据处理\n",
      "\t\t</td><td>\n",
      "\t\t\t<a href=\"/tutorials/data-manipulation/scraping/\">\n",
      "\t\t\t\t爬虫</a>\n",
      "\t\t</td><td>\n",
      "\t\t\t3:00\n",
      "\t\t</td><td>\n",
      "\t\t\t<img src=\"/static/img/course_cover/scraping.jpg\">\n",
      "\t\t</td>\n",
      "\t</tr>\n",
      "\n",
      "</table>\n",
      "\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "# if has Chinese, apply decode()\n",
    "html = urlopen(\"https://mofanpy.com/static/scraping/table.html\").read().decode('utf-8')\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以, 我们可以用 soup 将这些 <img> tag 全部找出来, 但是每一个 img 的链接(src)都可能不同. 或者每一个图片有的可能是 jpg 有的是 png, 如果我们只想挑选 jpg 形式的图片, 我们就可以用这样一个正则 r'.*?\\.jpg' 来选取. 把正则的 compile 形式放到 BeautifulSoup 的功能中, 就能选到符合要求的图片链接了."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/img/course_cover/tf.jpg\n",
      "/static/img/course_cover/rl.jpg\n",
      "/static/img/course_cover/scraping.jpg\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, features='html.parser')\n",
    "\n",
    "img_links = soup.find_all(\"img\", {\"src\": re.compile('.*?\\.jpg')})\n",
    "for link in img_links:\n",
    "    print(link['src'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "又或者我们发现, 我想选一些课程的链接, 而这些链接都有统一的形式, 就是开头都会有 https://morvan., 那我就将这个定为一个正则的规则, 让 BeautifulSoup 帮我找到符合这个规则的链接."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tutorials/data-manipulation/scraping/\n",
      "/tutorials/machine-learning/tensorflow/\n",
      "/tutorials/machine-learning/reinforcement-learning/\n",
      "/tutorials/data-manipulation/scraping/\n"
     ]
    }
   ],
   "source": [
    "course_links = soup.find_all('a', {'href': re.compile('/tutorials*')})\n",
    "for link in course_links:\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "学习了这么多实用的方法, 我们接下来就来做一个小实战, 让我们的爬虫在百度百科上自由爬行, 在各个百科网页上跳来跳去.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}